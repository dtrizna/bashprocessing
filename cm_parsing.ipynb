{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600240283426",
   "display_name": "Python 3.7.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bashlex # parsing library #1\n",
    "import bashlint # parsing library #2\n",
    "from collections import Counter, OrderedDict\n",
    "from pprint import pprint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'all.cm', encoding='utf-8') as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with `bashlex` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['__builtins__',\n '__cached__',\n '__doc__',\n '__file__',\n '__loader__',\n '__name__',\n '__package__',\n '__path__',\n '__spec__',\n 'ast',\n 'errors',\n 'flags',\n 'heredoc',\n 'parse',\n 'parser',\n 'parsesingle',\n 'parsetab',\n 'shutils',\n 'split',\n 'state',\n 'subst',\n 'tokenizer',\n 'utils',\n 'yacc']"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "dir(bashlex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "top -b -d2 -s1 | sed -e '1,/USERNAME/d' | sed -e '1,/^$/d'\n\n['top', '-b', '-d2', '-s1', '|', 'sed', '-e', '1,/USERNAME/d', '|', 'sed', '-e', '1,/^$/d', '\\n']\n"
    }
   ],
   "source": [
    "print(data[0])\n",
    "print(list(bashlex.split(data[0]))) # splitting first command to elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'list'>\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "tp = bashlex.parse(data[0]) # parsing first command \n",
    "print(type(tp))\n",
    "len(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'bashlex.ast.node'>\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "PipelineNode(parts=[CommandNode(parts=[WordNode(parts=[] pos=(0, 3) word='top'), WordNode(parts=[] pos=(4, 6) word='-b'), WordNode(parts=[] pos=(7, 10) word='-d2'), WordNode(parts=[] pos=(11, 14) word='-s1')] pos=(0, 14)), PipeNode(pipe='|' pos=(15, 16)), CommandNode(parts=[WordNode(parts=[] pos=(17, 20) word='sed'), WordNode(parts=[] pos=(21, 23) word='-e'), WordNode(parts=[] pos=(24, 39) word='1,/USERNAME/d')] pos=(17, 39)), PipeNode(pipe='|' pos=(40, 41)), CommandNode(parts=[WordNode(parts=[] pos=(42, 45) word='sed'), WordNode(parts=[] pos=(46, 48) word='-e'), WordNode(parts=[] pos=(49, 58) word='1,/^$/d')] pos=(42, 58))] pos=(0, 58))"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "print(type(tp[0]))\n",
    "tp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['__weakref__', 'dump', 'kind', 'parts', 'pos']"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "dir(tp[0])[-5:] # only few methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PipelineNode(pos=(0, 58), parts=[\n  CommandNode(pos=(0, 14), parts=[\n    WordNode(pos=(0, 3), word='top'),\n    WordNode(pos=(4, 6), word='-b'),\n    WordNode(pos=(7, 10), word='-d2'),\n    WordNode(pos=(11, 14), word='-s1'),\n  ]),\n  PipeNode(pipe='|', pos=(15, 16)),\n  CommandNode(pos=(17, 39), parts=[\n    WordNode(pos=(17, 20), word='sed'),\n    WordNode(pos=(21, 23), word='-e'),\n    WordNode(pos=(24, 39), word='1,/USERNAME/d'),\n  ]),\n  PipeNode(pipe='|', pos=(40, 41)),\n  CommandNode(pos=(42, 58), parts=[\n    WordNode(pos=(42, 45), word='sed'),\n    WordNode(pos=(46, 48), word='-e'),\n    WordNode(pos=(49, 58), word='1,/^$/d'),\n  ]),\n])\n"
    }
   ],
   "source": [
    "print(tp[0].dump()) # dump allows to observe parts in pretty way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CommandNode` - have set of specific command elements  \n",
    "`PipeNode` - separators  \n",
    "`WordNode` - element of CommandNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[CommandNode(parts=[WordNode(parts=[] pos=(0, 3) word='top'), WordNode(parts=[] pos=(4, 6) word='-b'), WordNode(parts=[] pos=(7, 10) word='-d2'), WordNode(parts=[] pos=(11, 14) word='-s1')] pos=(0, 14)), PipeNode(pipe='|' pos=(15, 16)), CommandNode(parts=[WordNode(parts=[] pos=(17, 20) word='sed'), WordNode(parts=[] pos=(21, 23) word='-e'), WordNode(parts=[] pos=(24, 39) word='1,/USERNAME/d')] pos=(17, 39)), PipeNode(pipe='|' pos=(40, 41)), CommandNode(parts=[WordNode(parts=[] pos=(42, 45) word='sed'), WordNode(parts=[] pos=(46, 48) word='-e'), WordNode(parts=[] pos=(49, 58) word='1,/^$/d')] pos=(42, 58))]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0, 58)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "print(tp[0].parts) # returns all the pipeline parts in list\n",
    "tp[0].pos # displays position of this specific element in original string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "for a in `find . -name '*.py'` ; do cp \"$a\" \"$a.cp\" ; echo \"Added line\" > \"$a\" ; cat \"$a.cp\" >> \"$a\" ; rm \"$a.cp\" ; done\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['for',\n 'a',\n 'in',\n \"`find . -name '*.py'`\",\n ';',\n 'do',\n 'cp',\n '$a',\n '$a.cp',\n ';',\n 'echo',\n 'Added line',\n '>',\n '$a',\n ';',\n 'cat',\n '$a.cp',\n '>>',\n '$a',\n ';',\n 'rm',\n '$a.cp',\n ';',\n 'done',\n '\\n']"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "print(data[48]) # test on more complex command\n",
    "\n",
    "list(bashlex.split(data[48]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1\n"
    }
   ],
   "source": [
    "tp2 = bashlex.parse(data[48])\n",
    "print(len(tp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ForNode(pos=(0, 120), parts=[\n  ReservedwordNode(pos=(0, 3), word='for'),\n  WordNode(pos=(4, 5), word='a'),\n  ReservedwordNode(pos=(6, 8), word='in'),\n  WordNode(pos=(9, 30), word=\"`find . -name '*.py'`\", parts=[\n    CommandsubstitutionNode(command=\n      CommandNode(pos=(10, 29), parts=[\n        WordNode(pos=(10, 14), word='find'),\n        WordNode(pos=(15, 16), word='.'),\n        WordNode(pos=(17, 22), word='-name'),\n        WordNode(pos=(23, 29), word='*.py'),\n      ]), pos=(9, 30)),\n  ]),\n  ReservedwordNode(pos=(31, 32), word=';'),\n  ReservedwordNode(pos=(33, 35), word='do'),\n  ListNode(pos=(36, 115), parts=[\n      CommandNode(pos=(36, 51), parts=[\n        WordNode(pos=(36, 38), word='cp'),\n        WordNode(pos=(39, 43), word='$a', parts=[\n          ParameterNode(pos=(40, 42), value='a'),\n        ]),\n        WordNode(pos=(44, 51), word='$a.cp', parts=[\n          ParameterNode(pos=(45, 47), value='a'),\n        ]),\n      ]),\n      OperatorNode(op=';', pos=(52, 53)),\n      CommandNode(pos=(54, 78), parts=[\n        WordNode(pos=(54, 58), word='echo'),\n        WordNode(pos=(59, 71), word='Added line'),\n        RedirectNode(output=\n          WordNode(pos=(74, 78), word='$a', parts=[\n            ParameterNode(pos=(75, 77), value='a'),\n          ]), pos=(72, 78), type='>'),\n      ]),\n      OperatorNode(op=';', pos=(79, 80)),\n      CommandNode(pos=(81, 100), parts=[\n        WordNode(pos=(81, 84), word='cat'),\n        WordNode(pos=(85, 92), word='$a.cp', parts=[\n          ParameterNode(pos=(86, 88), value='a'),\n        ]),\n        RedirectNode(output=\n          WordNode(pos=(96, 100), word='$a', parts=[\n            ParameterNode(pos=(97, 99), value='a'),\n          ]), pos=(93, 100), type='>>'),\n      ]),\n      OperatorNode(op=';', pos=(101, 102)),\n      CommandNode(pos=(103, 113), parts=[\n        WordNode(pos=(103, 105), word='rm'),\n        WordNode(pos=(106, 113), word='$a.cp', parts=[\n          ParameterNode(pos=(107, 109), value='a'),\n        ]),\n      ]),\n      OperatorNode(op=';', pos=(114, 115)),\n    ]),\n  ReservedwordNode(pos=(116, 120), word='done'),\n])\n"
    }
   ],
   "source": [
    "print(tp2[0].list[0].dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\nTrue\n"
    }
   ],
   "source": [
    "print(isinstance(tp2,(list,dict))) # check of isinstance\n",
    "print(isinstance(tp2[0],(bashlex.ast.node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[ForNode(parts=[ReservedwordNode(pos=(0, 3) word='for'), WordNode(parts=[] pos=(4, 5) word='a'), ReservedwordNode(pos=(6, 8) word='in'), WordNode(parts=[CommandsubstitutionNode(command=CommandNode(parts=[WordNode(parts=[] pos=(10, 14) word='find'), WordNode(parts=[] pos=(15, 16) word='.'), WordNode(parts=[] pos=(17, 22) word='-name'), WordNode(parts=[] pos=(23, 29) word='*.py')] pos=(10, 29)) pos=(9, 30))] pos=(9, 30) word=\"`find . -name '*.py'`\"), ReservedwordNode(pos=(31, 32) word=';'), ReservedwordNode(pos=(33, 35) word='do'), ListNode(parts=[CommandNode(parts=[WordNode(parts=[] pos=(36, 38) word='cp'), WordNode(parts=[ParameterNode(pos=(40, 42) value='a')] pos=(39, 43) word='$a'), WordNode(parts=[ParameterNode(pos=(45, 47) value='a')] pos=(44, 51) word='$a.cp')] pos=(36, 51)), OperatorNode(op=';' pos=(52, 53)), CommandNode(parts=[WordNode(parts=[] pos=(54, 58) word='echo'), WordNode(parts=[] pos=(59, 71) word='Added line'), RedirectNode(heredoc=None input=None output=WordNode(parts=[ParameterNode(pos=(75, 77) value='a')] pos=(74, 78) word='$a') pos=(72, 78) type='>')] pos=(54, 78)), OperatorNode(op=';' pos=(79, 80)), CommandNode(parts=[WordNode(parts=[] pos=(81, 84) word='cat'), WordNode(parts=[ParameterNode(pos=(86, 88) value='a')] pos=(85, 92) word='$a.cp'), RedirectNode(heredoc=None input=None output=WordNode(parts=[ParameterNode(pos=(97, 99) value='a')] pos=(96, 100) word='$a') pos=(93, 100) type='>>')] pos=(81, 100)), OperatorNode(op=';' pos=(101, 102)), CommandNode(parts=[WordNode(parts=[] pos=(103, 105) word='rm'), WordNode(parts=[ParameterNode(pos=(107, 109) value='a')] pos=(106, 113) word='$a.cp')] pos=(103, 113)), OperatorNode(op=';' pos=(114, 115))] pos=(36, 115)), ReservedwordNode(pos=(116, 120) word='done')] pos=(0, 120))]"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "tp2[0].list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate until get all basic elements\n",
    "\n",
    "Output of `bashlex.parse()` is list.  \n",
    "List has elements of `bashlex.ast.node` which may have either `list`, `parts` or `command` properties (at least figured those two by now) that contain next elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iterate_bashlex(input_object):\n",
    "    output = Counter()\n",
    "    if isinstance(input_object, list):\n",
    "        for element in input_object:\n",
    "            output += iterate_bashlex(element)\n",
    "    elif isinstance(input_object, bashlex.ast.node):\n",
    "        object_methods = [x for x in dir(input_object) if '__' not in x]\n",
    "        if 'command' in object_methods:\n",
    "            output += iterate_bashlex(input_object.command)\n",
    "        elif 'list' in object_methods:\n",
    "            for element in input_object.list:\n",
    "                output += iterate_bashlex(element)\n",
    "        elif 'parts' in object_methods:        \n",
    "            if input_object.parts:\n",
    "                for part in input_object.parts:\n",
    "                    output += iterate_bashlex(part)\n",
    "            else:\n",
    "                output[input_object.word] += 1\n",
    "        elif 'word' in object_methods:\n",
    "            output[input_object.word] += 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Counter({'for': 1, 'a': 1, 'in': 1, 'find': 1, '.': 1, '-name': 1, '*.py': 1, ';': 1, 'do': 1, 'cp': 1, 'echo': 1, 'Added line': 1, 'cat': 1, 'rm': 1, 'done': 1})\n"
    }
   ],
   "source": [
    "for nodes in tp2:\n",
    "    token_dict = iterate_bashlex(nodes)\n",
    "print(token_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on full corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'top': 10, '-b': 5, '-d2': 1, '-s1': 1, 'sed': 4, '-e': 2, '1,/USERNAME/d': 1, '1,/^$/d': 1, '-n': 4, '1': 2, '-u': 1, 'abc': 1, 'awk': 3, 'NR>7 { sum += $9; } END { print sum; }': 1, '-d': 1, '5': 1, '2': 1, '$1 == \"PID\" {block_num++; next} block_num == 2 {sum += $9;} END {print sum}': 1, '-bn1': 3, 'grep': 3, 'zombie': 2, '/Cpu/p': 1, '{print $4\" \"$6\" \"$8\" \"$10}': 1, '-n1': 3, '-c': 1, 'processname': 1, 's/\\\\(.*\\\\)$/\\\\1__CUSTOM_LINE_MARKER/g': 1}\n"
    }
   ],
   "source": [
    "# testing bashlex functions with lists\n",
    "alldict = Counter()\n",
    "for command in data[0:10]:\n",
    "    for node in bashlex.parse(command):\n",
    "        alldict += iterate_bashlex(node)\n",
    "print(dict(alldict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Parsing errors encountered on 1.01 % of data.\n"
    }
   ],
   "source": [
    "# trying on all data\n",
    "alldict = Counter()\n",
    "errors = 0\n",
    "for i,command in enumerate(data):\n",
    "    print(f'{i}/{len(data)}',end='\\r')\n",
    "    try:\n",
    "        for node in bashlex.parse(command):\n",
    "            alldict += iterate_bashlex(node)\n",
    "    except bashlex.errors.ParsingError as ex:\n",
    "        #print(command, ex)\n",
    "        errors += 1\n",
    "    except NotImplementedError as ex:\n",
    "        #print(command, ex)\n",
    "        errors += 1\n",
    "    except TypeError as ex:\n",
    "        #print(command, ex)\n",
    "        errors += 1\n",
    "\n",
    "print(f'Parsing errors encountered on {errors*100/len(data):.2f} % of data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "8724"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# unique elements\n",
    "len(alldict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1950\n1074\n"
    }
   ],
   "source": [
    "# only ~2k unique elements appear more than 3 times\n",
    "print(len({k:v for k,v in alldict.items() if v >= 3})) \n",
    "# only ~1k unique elements appear more than 5 times\n",
    "print(len({k:v for k,v in alldict.items() if v >= 5})) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('find', 7747),\n ('.', 3728),\n ('-name', 3563),\n ('-type', 3354),\n ('f', 2438),\n ('{}', 2274),\n ('-exec', 2086),\n (';', 1823),\n ('xargs', 1523),\n ('grep', 1333),\n ('-print', 927),\n ('d', 848),\n ('/', 778),\n ('1', 740),\n ('-print0', 725),\n ('sort', 704),\n ('-o', 667),\n ('-l', 655),\n ('sed', 611),\n ('rm', 611)]"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# 20 elements with highest counts\n",
    "alldict.most_common(20)"
   ]
  },
  {
   "source": [
    "## Investigating parsin errors\n",
    "\n",
    "Around ~5k of Counter() elements appears only once - this means that they're large parts of original dataset w/ poor parsing..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "5204\n"
    }
   ],
   "source": [
    "print(len({k:v for k,v in alldict.items() if v == 1})) "
   ]
  },
  {
   "source": [
    "Investigating specific examples of poorly parsed commands.."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('\"{\" \"\\\\C-v{}\\\\ei\"', 1),\n ('vi-insert', 1),\n ('attrib', 1),\n ('inotifywait', 1),\n ('\\\\./[a-f0-9\\\\-]{36}\\\\.jpg', 1),\n (\"unzip -c %p | grep -q '<stringWithOrWithoutSpacesToFind>' && echo %pn\", 1),\n ('#*', 1),\n ('/ /_/', 1),\n ('-Rd', 1),\n ('4444', 1),\n ('10022', 1),\n ('/^[[:space:]]*$/d', 1),\n ('HOST', 1),\n ('ForwardAgent=yes', 1),\n ('IdentitiesOnly=yes', 1),\n ('LogLevel=FATAL', 1),\n ('DSAAuthentication=yes', 1),\n ('Compression=yes', 1),\n ('vagrant@127.0.0.1', 1)]"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# 20 least common\n",
    "alldict.most_common()[:-20:-1]"
   ]
  },
  {
   "source": [
    "Right away it's sen that algorithm does poorly on identifying flags and their parameters separated by `=` sign."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'ssh vagrant@127.0.0.1 -p 2222 -o Compression=yes -o DSAAuthentication=yes -o LogLevel=FATAL -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o IdentitiesOnly=yes -i ~/.vagrant.d/less_insecure_private_key -o ForwardAgent=yes\\n'"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "bad_example = [x for x in data if 'LogLevel=FATAL' in x][0]\n",
    "be = bashlex.parse(bad_example)\n",
    "bad_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1\nCommandNode(pos=(0, 235), parts=[\n  WordNode(pos=(0, 3), word='ssh'),\n  WordNode(pos=(4, 21), word='vagrant@127.0.0.1'),\n  WordNode(pos=(22, 24), word='-p'),\n  WordNode(pos=(25, 29), word='2222'),\n  WordNode(pos=(30, 32), word='-o'),\n  WordNode(pos=(33, 48), word='Compression=yes'),\n  WordNode(pos=(49, 51), word='-o'),\n  WordNode(pos=(52, 73), word='DSAAuthentication=yes'),\n  WordNode(pos=(74, 76), word='-o'),\n  WordNode(pos=(77, 91), word='LogLevel=FATAL'),\n  WordNode(pos=(92, 94), word='-o'),\n  WordNode(pos=(95, 119), word='StrictHostKeyChecking=no'),\n  WordNode(pos=(120, 122), word='-o'),\n  WordNode(pos=(123, 151), word='UserKnownHostsFile=/dev/null'),\n  WordNode(pos=(152, 154), word='-o'),\n  WordNode(pos=(155, 173), word='IdentitiesOnly=yes'),\n  WordNode(pos=(174, 176), word='-i'),\n  WordNode(pos=(177, 215), word='~/.vagrant.d/less_insecure_private_key', parts=[\n    TildeNode(pos=(177, 178), value='~'),\n  ]),\n  WordNode(pos=(216, 218), word='-o'),\n  WordNode(pos=(219, 235), word='ForwardAgent=yes'),\n])\n"
    }
   ],
   "source": [
    "print(len(be))\n",
    "print(be[0].dump())"
   ]
  },
  {
   "source": [
    "Indeed flags are not parsed by `bashlex` itself and are not weakness of `iterate_bashlex` function.  \n",
    "  \n",
    "Another case is full `unzip` comand. Presumably it is embedded into another one - let's take a look:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'find . -iname \\'*.jar\\' -printf \"unzip -c %p | grep -q \\'<stringWithOrWithoutSpacesToFind>\\' && echo %p\\\\n\" | sh\\n'"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "bad_example2 = [x for x in data if 'stringWithOrWithoutSpacesToFind' in x][0]\n",
    "be2 = bashlex.parse(bad_example2)\n",
    "bad_example2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1\nPipelineNode(pos=(0, 107), parts=[\n  CommandNode(pos=(0, 102), parts=[\n    WordNode(pos=(0, 4), word='find'),\n    WordNode(pos=(5, 6), word='.'),\n    WordNode(pos=(7, 13), word='-iname'),\n    WordNode(pos=(14, 21), word='*.jar'),\n    WordNode(pos=(22, 29), word='-printf'),\n    WordNode(pos=(30, 102), word=\"unzip -c %p | grep -q '<stringWithOrWithoutSpacesToFind>' && echo %pn\"),\n  ]),\n  PipeNode(pipe='|', pos=(103, 104)),\n  CommandNode(pos=(105, 107), parts=[\n    WordNode(pos=(105, 107), word='sh'),\n  ]),\n])\n"
    }
   ],
   "source": [
    "print(len(be2))\n",
    "print(be2[0].dump())"
   ]
  },
  {
   "source": [
    "Again we see that it indeed is `bashlex` weakness. Will try to give every single element to additional parsing cycle."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bashlex_wrapper(command, cntr):\n",
    "    global ERR\n",
    "    try:\n",
    "        nodes = bashlex.parse(command)\n",
    "        return nodes\n",
    "    except (bashlex.errors.ParsingError, NotImplementedError, TypeError):\n",
    "        for element in re.split(r\" |,|{|}\",command):\n",
    "            cntr[element.strip()] += 1\n",
    "        ERR += 1\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_word(input_object, output, skipparse=False):\n",
    "    # TRY TO PARSE COMMAND AGAIN    \n",
    "    neword = ''\n",
    "    size = 1\n",
    "    word = re.sub(r\"[<>#{}]\", \"\", input_object.word).strip()\n",
    "    #word = input_object.word.strip(\"<>\")\n",
    "    if len(input_object.word) > 20:\n",
    "        p = bashlex_wrapper(word, output)\n",
    "        if p:\n",
    "            try:\n",
    "                size = len(p[0].parts)\n",
    "            except AttributeError:\n",
    "                size = len(p[0].list)\n",
    "    if size > 1: # if size > 1 then parsing found something new\n",
    "        for node in p:\n",
    "            output += iterate_bashlex2(node)\n",
    "        return output\n",
    "    # ADDED TO PARSE FLAGS WITH '=' BETTER\n",
    "    if '=' in input_object.word and '==' not in input_object.word:\n",
    "        l = input_object.word.split('=')\n",
    "        if 'chmod' in input_object.word.lower():\n",
    "            output[l[0]] += 1\n",
    "            output['='.join(l[1:])] += 1\n",
    "        elif len(l) == 2:\n",
    "            output[l[0]] += 1\n",
    "            output[l[1]] += 1\n",
    "        else:\n",
    "            output[input_object.word] += 1            \n",
    "    # STANDARD CASE\n",
    "    else:\n",
    "        output[input_object.word] += 1\n",
    "    return output\n",
    "\n",
    "\n",
    "def iterate_bashlex2(input_object):\n",
    "    output = Counter()\n",
    "    if isinstance(input_object, list):\n",
    "        for element in input_object:\n",
    "            output += iterate_bashlex2(element)\n",
    "    elif isinstance(input_object, bashlex.ast.node):\n",
    "        object_methods = [x for x in dir(input_object) if '__' not in x]\n",
    "        if 'command' in object_methods:\n",
    "            output += iterate_bashlex2(input_object.command)\n",
    "        elif 'list' in object_methods:\n",
    "            for element in input_object.list:\n",
    "                output += iterate_bashlex2(element)\n",
    "        elif 'parts' in object_methods:        \n",
    "            if input_object.parts:\n",
    "                for part in input_object.parts:\n",
    "                    output += iterate_bashlex2(part)\n",
    "            else:\n",
    "                output = parse_word(input_object, output)\n",
    "        elif 'word' in object_methods:\n",
    "            output = parse_word(input_object, output)\n",
    "        # Working on default specific types\n",
    "        elif 'value' in object_methods:\n",
    "            output[input_object.value] += 1\n",
    "        elif \"pipe\" in object_methods:\n",
    "            output[input_object.pipe] += 1\n",
    "        elif \"op\" in object_methods:\n",
    "            output[input_object.op] += 1\n",
    "        elif \"type\" in object_methods:\n",
    "            output[input_object.type] += 1\n",
    "        else:\n",
    "            print(\"Weird case:\", input_object)\n",
    "            import pdb; pdb.set_trace()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Counter({'ssh': 1,\n         'vagrant@127.0.0.1': 1,\n         '-p': 1,\n         '2222': 1,\n         '-o': 7,\n         'Compression': 1,\n         'yes': 4,\n         'DSAAuthentication': 1,\n         'LogLevel': 1,\n         'FATAL': 1,\n         'StrictHostKeyChecking': 1,\n         'no': 1,\n         'UserKnownHostsFile': 1,\n         '/dev/null': 1,\n         'IdentitiesOnly': 1,\n         '-i': 1,\n         '~': 1,\n         'ForwardAgent': 1})"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "iterate_bashlex2(be)"
   ]
  },
  {
   "source": [
    "Now it's seen that flag/value pairs with `=` sign are splitted correctly for problematic example.  \n",
    "Let's check that on command within command:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Counter({'find': 1,\n         '.': 1,\n         '-iname': 1,\n         '*.jar': 1,\n         '-printf': 1,\n         'unzip': 1,\n         '-c': 1,\n         '%p': 1,\n         '|': 2,\n         'grep': 1,\n         '-q': 1,\n         'stringWithOrWithoutSpacesToFind': 1,\n         '&&': 1,\n         'echo': 1,\n         '%pn': 1,\n         'sh': 1})"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "iterate_bashlex2(be2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Parsing errors encountered on 3.15 % of data.\n"
    }
   ],
   "source": [
    "# trying on all data\n",
    "alldict2 = Counter()\n",
    "ERR = 0\n",
    "for i,command in enumerate(data):\n",
    "    nodes = None\n",
    "    print(f'{i}/{len(data)}',end='\\r')\n",
    "    nodes = bashlex_wrapper(command, alldict2)\n",
    "    if nodes:\n",
    "        for node in nodes:\n",
    "            alldict2 += iterate_bashlex2(node)\n",
    "\n",
    "print(f'Parsing errors encountered on {ERR*100/len(data):.2f} % of data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "6188\n"
    }
   ],
   "source": [
    "print(len({k:v for k,v in alldict2.items() if v == 1})) "
   ]
  },
  {
   "source": [
    "Nevertheless number of unique elements is approximately the same, parsing now is better. Increase is due to fact that amount of command elements increased as well.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "85100\n101232\n"
    }
   ],
   "source": [
    "print(sum(alldict.values()))\n",
    "print(sum(alldict2.values()))"
   ]
  },
  {
   "source": [
    "As example, see flags `LogLevel` or `--chmod` that appar in dataset. Previously they wasn't parsed at all...  \n",
    "`/dev/null` counter in this case increased as well. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'LogLevel': 2}\n{'--chmod': 4}\n{'/dev/null': 44}\n"
    }
   ],
   "source": [
    "print({k:v for k,v in alldict2.items() if k == \"LogLevel\"}) \n",
    "print({k:v for k,v in alldict2.items() if k == \"--chmod\"})\n",
    "print({k:v for k,v in alldict2.items() if k == \"/dev/null\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'/dev/null': 28}\n"
    }
   ],
   "source": [
    "# Baseline value - should increase after correct parsing\n",
    "print({k:v for k,v in alldict.items() if k == \"/dev/null\"}) "
   ]
  },
  {
   "source": [
    "### Looking on next problem\n",
    "\n",
    "Still relatively large amount of single time appearing tags.  \n",
    "Looking on them it is seen that they're sort of unique elements and not parsing errors anymore..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('\"{\" \"\\\\C-v{}\\\\ei\"', 1),\n ('vi-insert', 1),\n ('attrib', 1),\n ('inotifywait', 1),\n ('\\\\./[a-f0-9\\\\-]{36}\\\\.jpg', 1),\n ('stringWithOrWithoutSpacesToFind', 1),\n ('#*', 1),\n ('/ /_/', 1),\n ('\"$(', 1),\n ('DIR=\"$(', 1),\n ('pwd)/$(basename', 1),\n ('\"$(dirname', 1),\n ('ABSOLUTE_PATH=\"$(cd', 1),\n ('-Rd', 1),\n ('4444', 1),\n ('10022', 1),\n ('/^[[:space:]]*$/d', 1),\n ('ForwardAgent', 1),\n ('IdentitiesOnly', 1),\n ('FATAL', 1),\n ('DSAAuthentication', 1),\n ('Compression', 1),\n ('vagrant@127.0.0.1', 1),\n ('--host', 1),\n ('vagrant@localhost', 1),\n ('s/n/', 1),\n ('s/@/', 1),\n ('s/s/', 1),\n ('s/^s+/-o@/', 1)]"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "alldict2.most_common()[:-30:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}