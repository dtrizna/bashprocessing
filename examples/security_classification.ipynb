{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "f18a4039b52cba542189536e87fe9a35f2c3ec28f83d49c4da45938af89bff90"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bashprocessing import Parser\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "RANDOM = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/bashlex.cm') as f1:\n",
    "    benign = f1.readlines()\n",
    "\n",
    "with open('data/malicious.cm') as f2:\n",
    "    malicious = f2.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "12607\n123\n"
    }
   ],
   "source": [
    "# heavily imbalanced data - as always in security ...\n",
    "print(len(benign))\n",
    "print(len(malicious))"
   ]
  },
  {
   "source": [
    "# Creating test and validation sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We just can't use sklearn's `train_test_split()` as is, because many malicious behavior commands have totally different pattern and purpose. Therefore, we need to find specific command subset, that characterize some family of malicious commands, and is in necessary amount to be present in both train and test sets.\n",
    "\n",
    "*nix `/usr/bin/find` binary is often used query filesystem on behalf of specific files and their parameters. Heavily utilized by both system administrators and security threat actors during system enumeration. Some subset of `find` commands present in both datasets:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "7826\n64\n"
    }
   ],
   "source": [
    "print(len([x for x in benign if 'find' in x]))\n",
    "\n",
    "print(len([x for x in malicious if 'find' in x]))"
   ]
  },
  {
   "source": [
    "Similar situation with network connectivity - both valid commands and malicious callbacks (called *reverse shells*) have network information within (in our dataset all remote host specification is normalized to be `example.com`), and present in both datasets:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "77\n30\n"
    }
   ],
   "source": [
    "# commands that perform connections to remote hosts (normalized so host is specified as example.com)\n",
    "print(len([x for x in benign if 'example.com' in x]))\n",
    "print(len([x for x in malicious if 'example.com' in x]))"
   ]
  },
  {
   "source": [
    "Both of these command patterns will be segregated to, so some subset is present in train set, and other subset in test set.."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def give_test_by_pattern(inputlist, pattern, size=None):\n",
    "    pattern_list = shuffle([x for x in inputlist if pattern in x], random_state=RANDOM)\n",
    "    non_pattern_list = [x for x in inputlist if pattern not in x]\n",
    "    \n",
    "    if not size:\n",
    "        size = int(0.5 * len(pattern_list))\n",
    "    \n",
    "    pattern_trainset = [x for x in pattern_list][size:]\n",
    "    pattern_testset = [x for x in pattern_list][:size]\n",
    "\n",
    "    trainset = pattern_trainset + non_pattern_list\n",
    "    return trainset, pattern_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(benign, malicious, patterns):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = [], [], [], []\n",
    "    cropped_train = [benign, malicious]\n",
    "\n",
    "    for pattern in patterns:\n",
    "        \n",
    "        tr, te = give_test_by_pattern(cropped_train[1], pattern)\n",
    "        X_test.extend(te)\n",
    "        y_test.extend([1]*len(te))\n",
    "        cropped_train[1] = tr\n",
    "\n",
    "        tr, te = give_test_by_pattern(cropped_train[0], pattern, size=len(te))\n",
    "        X_test.extend(te)\n",
    "        y_test.extend([0]*len(te))\n",
    "        cropped_train[0] = tr\n",
    "\n",
    "    X_train, y_train = shuffle(cropped_train[0] + cropped_train[1], \\\n",
    "                                [0] * len(cropped_train[0]) + [1] * len(cropped_train[1]), \\\n",
    "                                random_state=RANDOM) \n",
    "    X_test, y_test = shuffle(X_test, y_test, random_state=RANDOM)\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "12626 104\n"
    }
   ],
   "source": [
    "X_train_cm, X_test_cm, y_train, y_test = create_datasets(benign, malicious, [\"find\", \"example.com\", \"python\", \"php\"])\n",
    "print(len(X_train_cm), len(X_test_cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "12730\n12730\n12730\n"
    }
   ],
   "source": [
    "# sanity check\n",
    "print(len(X_train_cm + X_test_cm))\n",
    "print(len(y_train + y_test))\n",
    "print(len(malicious + benign))"
   ]
  },
  {
   "source": [
    "# Encoding using `bashprocessing`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n (12626, 1000)\n"
    }
   ],
   "source": [
    "from bashprocessing import Parser\n",
    "\n",
    "p = Parser(verbose=True)\n",
    "cntr , corpus = p.parse(X_train_cm)\n",
    "X_train = p.encode(mode=\"onehot\", top_tokens=1000)\n",
    "print(\"\\n\",X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(104, 1000)\n"
    }
   ],
   "source": [
    "p = Parser(verbose=True)\n",
    "_,_ = p.parse(X_test_cm)\n",
    "X_test = p.encode(mode=\"onehot\", top_tokens=1000)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "source": [
    "# RandomForestClassifier and Oversampling\n",
    "\n",
    "If we train model on data as is we get all predictions as benign and accuracy of exact 50% (due to fast that our test set have exact same amount of values from both classes).."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.5\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(y_pred)\n"
   ]
  },
  {
   "source": [
    "This is due to fact that we have negligble count of malicious examples in our training set.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "In test set:\n\tMalicious commands: 50.0 %\n\nIn train set:\n\tMalicious commands: 0.5623 %\n"
    }
   ],
   "source": [
    "def class_percentage(y):\n",
    "    u,c = np.unique(y, return_counts=True)\n",
    "    neg,pos = c\n",
    "    print(f\"Malicious commands: {round(pos*100/(neg+pos),4)} %\")\n",
    "\n",
    "print(\"In test set:\\n\\t\", end=\"\")\n",
    "class_percentage(y_test)\n",
    "print(\"\\nIn train set:\\n\\t\", end=\"\")\n",
    "class_percentage(y_train)"
   ]
  },
  {
   "source": [
    "Therefore, we need to implement oversampling, so model is able to train itself on malicious examples."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy='minority', random_state=RANDOM)\n",
    "\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(12626, 1000)\n(25110, 1000)\n"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nIn resampled train set:\n\tMalicious commands: 50.0 %\n"
    }
   ],
   "source": [
    "print(\"\\nIn resampled train set:\\n\\t\", end=\"\")\n",
    "class_percentage(y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.5096153846153846\n"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=200)\n",
    "rfc.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 0 1 1 1 0\n 1 1 1 1 1 1 1 0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 1 1\n 1 1 0 0 1 1 1 0 0 1 1 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 1 0 1 1]\n"
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(np.array(y_test))"
   ]
  },
  {
   "source": [
    "Still predition is really poor and obviously biased towards benign class ...  \n",
    "On train set we have pretty good pattern learning:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9988849064117882\n"
    }
   ],
   "source": [
    "y_train_pred = rfc.predict(X_train_resampled)\n",
    "print(accuracy_score(y_train_resampled, y_train_pred))"
   ]
  }
 ]
}